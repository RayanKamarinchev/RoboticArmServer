{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507bfe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\raian\\anaconda3\\lib\\site-packages (8.3.228)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (2.9.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (0.24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: polars in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\raian\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raian\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in c:\\users\\raian\\anaconda3\\lib\\site-packages (from polars->ultralytics) (1.35.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53bb6c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fiftyone.types.dataset_types.YOLOv5Dataset"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.utils.yolo as fouy\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import os\n",
    "\n",
    "fo.types.YOLOv5Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c17e1ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to 'C:\\Users\\raian\\fiftyone\\open-images-v6\\train' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v6-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Sample: {\n",
       "    'id': '696798668eedb29fcff28c5d',\n",
       "    'media_type': 'image',\n",
       "    'filepath': 'C:\\\\Users\\\\raian\\\\fiftyone\\\\open-images-v6\\\\train\\\\data\\\\0000333f08ced1cd.jpg',\n",
       "    'tags': ['train'],\n",
       "    'metadata': None,\n",
       "    'created_at': datetime.datetime(2026, 1, 14, 13, 21, 42, 711000),\n",
       "    'last_modified_at': datetime.datetime(2026, 1, 14, 13, 21, 42, 711000),\n",
       "    'ground_truth': <Detections: {\n",
       "\n",
       "        'detections': [\n",
       "\n",
       "            <Detection: {\n",
       "\n",
       "\n",
       "                'id': '696798668eedb29fcff28c5c',\n",
       "\n",
       "\n",
       "                'attributes': {},\n",
       "\n",
       "\n",
       "                'tags': [],\n",
       "\n",
       "\n",
       "                'label': 'Box',\n",
       "\n",
       "\n",
       "                'bounding_box': [\n",
       "\n",
       "\n",
       "                    0.153206,\n",
       "\n",
       "\n",
       "                    0.06875,\n",
       "\n",
       "\n",
       "                    0.6977519999999999,\n",
       "\n",
       "\n",
       "                    0.8825000000000001,\n",
       "\n",
       "\n",
       "                ],\n",
       "\n",
       "\n",
       "                'mask': array([[False, False, False, ..., False, False, False],\n",
       "\n",
       "\n",
       "                       [False, False, False, ..., False, False, False],\n",
       "\n",
       "\n",
       "                       [False, False, False, ..., False, False, False],\n",
       "\n",
       "\n",
       "                       ...,\n",
       "\n",
       "\n",
       "                       [False, False, False, ..., False, False, False],\n",
       "\n",
       "\n",
       "                       [False, False, False, ..., False, False, False],\n",
       "\n",
       "\n",
       "                       [False, False, False, ..., False, False, False]]),\n",
       "\n",
       "\n",
       "                'mask_path': None,\n",
       "\n",
       "\n",
       "                'confidence': None,\n",
       "\n",
       "\n",
       "                'index': None,\n",
       "\n",
       "\n",
       "            }>,\n",
       "\n",
       "        ],\n",
       "\n",
       "    }>,\n",
       "}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v6\",\n",
    "    split=\"train\",\n",
    "    label_types=[\"segmentations\"],\n",
    "    classes=[\"Box\"]\n",
    ")\n",
    "\n",
    "sample = dataset.first()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)\n",
    "session.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f52d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Adhesive tape', 'Apple', 'Ball', 'Balloon', 'Beer', 'Bicycle wheel', 'Bird', 'Book', 'Boot', 'Bottle', 'Bowl', 'Box', 'Boy', 'Briefcase', 'Cake', 'Camera', 'Car', 'Carnivore', 'Cat', 'Chest of drawers', 'Christmas tree', 'Clothing', 'Coffee', 'Coffee cup', 'Computer keyboard', 'Couch', 'Cowboy hat', 'Dog', 'Dress', 'Drink', 'Facial tissue holder', 'Fedora', 'Filing cabinet', 'Flower', 'Flowerpot', 'Girl', 'Grapefruit', 'Guitar', 'Hat', 'High heels', 'Human body', 'Human ear', 'Human mouth', 'Ipod', 'Jeans', 'Kettle', 'Laptop', 'Lemon', 'Lipstick', 'Loveseat', 'Luggage and bags', 'Man', 'Mobile phone', 'Mouse', 'Muffin', 'Mug', 'Pastry', 'Peach', 'Pen', 'Pencil case', 'Person', 'Picture frame', 'Pillow', 'Pizza', 'Plastic bag', 'Platter', 'Printer', 'Rabbit', 'Rose', 'Scarf', 'Scissors', 'Sculpture', 'Shirt', 'Shorts', 'Sofa bed', 'Sombrero', 'Spoon', 'Strawberry', 'Studio couch', 'Suit', 'Suitcase', 'Sun hat', 'Tablet computer', 'Tap', 'Tart', 'Taxi', 'Teapot', 'Teddy bear', 'Tie', 'Toilet', 'Tomato', 'Toy', 'Trousers', 'Truck', 'Van', 'Vase', 'Washing machine', 'Waste container', 'Watch', 'Wheel', 'Wine', 'Woman']\n",
      "Train samples: 1877\n",
      "Val samples: 209\n",
      "Exporting train split\n",
      " 100% |███████████████| 1877/1877 [1.9m elapsed, 0s remaining, 17.1 samples/s]      \n",
      "Exporting val split\n",
      "Directory './yolo_dataset' already exists; export will be merged with existing files\n",
      " 100% |█████████████████| 209/209 [14.8s elapsed, 0s remaining, 17.1 samples/s]      \n",
      "✓ Export complete to: c:\\Users\\raian\\source\\repos\\Py\\RoboticArmApi\\src\\cv\\yolo_dataset\n",
      "yolo_dataset/\n",
      "  images/\n",
      "    train/\n",
      "    val/\n",
      "  labels/\n",
      "    train/\n",
      "    val/\n"
     ]
    }
   ],
   "source": [
    "export_dir = \"./yolo_dataset\"\n",
    "\n",
    "classes = dataset.distinct(\"ground_truth.detections.label\")\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "sample_ids = list(dataset.values(\"id\"))\n",
    "random.shuffle(sample_ids)\n",
    "\n",
    "split_idx = int(len(sample_ids) * 0.9)\n",
    "train_ids = sample_ids[:split_idx]\n",
    "val_ids = sample_ids[split_idx:]\n",
    "\n",
    "# Create views\n",
    "train_view = dataset.select(train_ids)\n",
    "val_view = dataset.select(val_ids)\n",
    "\n",
    "print(f\"Train samples: {len(train_view)}\")\n",
    "print(f\"Val samples: {len(val_view)}\")\n",
    "\n",
    "print(\"Exporting train split\")\n",
    "train_view.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=\"ground_truth\",\n",
    "    classes=classes,\n",
    "    split=\"train\",\n",
    "    use_masks=True\n",
    ")\n",
    "\n",
    "print(\"Exporting val split\")\n",
    "val_view.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=\"ground_truth\",\n",
    "    classes=classes,\n",
    "    split=\"val\",\n",
    "    use_masks=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Export complete to: {os.path.abspath(export_dir)}\")\n",
    "\n",
    "# Verify structure\n",
    "for root, dirs, files in os.walk(export_dir):\n",
    "    level = root.replace(export_dir, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8604696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-seg.pt to 'yolo11s-seg.pt': 100% ━━━━━━━━━━━━ 19.7MB 7.8MB/s 2.5s2.5s<0.1s0s\n",
      "New https://pypi.org/project/ultralytics/8.4.2 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.228  Python-3.13.5 torch-2.9.1+cpu CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./yolo_dataset/dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=box_segmentation, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\raian\\source\\repos\\Py\\RoboticArmApi\\src\\cv\\runs\\segment\\box_segmentation, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=102\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1   1513378  ultralytics.nn.modules.head.Segment          [102, 32, 128, [128, 256, 512]]\n",
      "YOLO11s-seg summary: 203 layers, 10,121,762 parameters, 10,121,746 gradients, 33.3 GFLOPs\n",
      "\n",
      "Transferred 555/561 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1720.6529.9 MB/s, size: 471.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\raian\\source\\repos\\Py\\RoboticArmApi\\src\\cv\\yolo_dataset\\labels\\train... 1877 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1877/1877 1.8Kit/s 1.1s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\raian\\source\\repos\\Py\\RoboticArmApi\\src\\cv\\yolo_dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2101.5713.1 MB/s, size: 382.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\raian\\source\\repos\\Py\\RoboticArmApi\\src\\cv\\yolo_dataset\\labels\\val... 209 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 209/209 2.0Kit/s 0.1s<0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\raian\\source\\repos\\Py\\RoboticArmApi\\src\\cv\\yolo_dataset\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\raian\\source\\repos\\Py\\RoboticArmApi\\src\\cv\\runs\\segment\\box_segmentation\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=9.4e-05, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\raian\\source\\repos\\Py\\RoboticArmApi\\src\\cv\\runs\\segment\\box_segmentation\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100         0G      1.088      3.249      5.971      1.322        117        640: 2% ──────────── 2/118 17.6s/it 34.7s<33:5640\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11s-seg.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m      4\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./yolo_dataset/dataset.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      6\u001b[0m     imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m,\n\u001b[0;32m      7\u001b[0m     batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m      8\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox_segmentation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[1;32mc:\\Users\\raian\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:778\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\raian\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:243\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train()\n",
      "File \u001b[1;32mc:\\Users\\raian\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:434\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_step()\n",
      "File \u001b[1;32mc:\\Users\\raian\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    624\u001b[0m     )\n\u001b[1;32m--> 625\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    627\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\raian\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m _engine_run_backward(\n\u001b[0;32m    355\u001b[0m     tensors,\n\u001b[0;32m    356\u001b[0m     grad_tensors_,\n\u001b[0;32m    357\u001b[0m     retain_graph,\n\u001b[0;32m    358\u001b[0m     create_graph,\n\u001b[0;32m    359\u001b[0m     inputs_tuple,\n\u001b[0;32m    360\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    361\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    362\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\raian\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    842\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    843\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = YOLO('yolo11s-seg.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data=f\"./yolo_dataset/dataset.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='box_segmentation'\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('runs/box_segmentation/weights/best.pt')\n",
    "\n",
    "for sample in dataset.select_fields(\"filepath\"):\n",
    "    results = model.predict(sample.filepath, conf=0.25)\n",
    "    \n",
    "    detections = []\n",
    "    for result in results:\n",
    "        if result.masks is not None:\n",
    "            for mask, box, conf, cls in zip(\n",
    "                result.masks.data, \n",
    "                result.boxes.xyxy,\n",
    "                result.boxes.conf,\n",
    "                result.boxes.cls\n",
    "            ):\n",
    "                detections.append(\n",
    "                    fo.Detection(\n",
    "                        label=model.names[int(cls)],\n",
    "                        confidence=float(conf),\n",
    "                        bounding_box=...,  # Convert box format\n",
    "                        mask=mask.cpu().numpy()\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "    sample[\"predictions\"] = fo.Detections(detections=detections)\n",
    "    sample.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
